# -*- coding: utf-8 -*-
"""testModelngrok.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16M_8EtjLNq8z29sYDMXN3Qa4TZXyL4cf
"""

from typing import List
from fastapi import FastAPI, File, UploadFile
from fastapi.responses import HTMLResponse, StreamingResponse

"""## Model"""

# Commented out IPython magic to ensure Python compatibility.
import torch
import torch.nn as nn
import torchvision.models as models
import torch.nn.functional as F

classes = ["cardboard", "glass", "metal", "paper", "plastic", "trash"]


def accuracy(outputs, labels):
    _, preds = torch.max(outputs, dim=1)
    return torch.tensor(torch.sum(preds == labels).item() / len(preds))


class ImageClassificationBase(nn.Module):
    def training_step(self, batch):
        images, labels = batch
        out = self(images)  # Generate predictions
        loss = F.cross_entropy(out, labels)  # Calculate loss
        return loss

    def validation_step(self, batch):
        images, labels = batch
        out = self(images)  # Generate predictions
        loss = F.cross_entropy(out, labels)  # Calculate loss
        acc = accuracy(out, labels)  # Calculate accuracy
        return {"val_loss": loss.detach(), "val_acc": acc}

    def validation_epoch_end(self, outputs):
        batch_losses = [x["val_loss"] for x in outputs]
        epoch_loss = torch.stack(batch_losses).mean()  # Combine losses
        batch_accs = [x["val_acc"] for x in outputs]
        epoch_acc = torch.stack(batch_accs).mean()  # Combine accuracies
        return {"val_loss": epoch_loss.item(), "val_acc": epoch_acc.item()}

    def epoch_end(self, epoch, result):
        print(
            "Epoch {}: train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}".format(
                epoch + 1, result["train_loss"], result["val_loss"], result["val_acc"]
            )
        )


# Define your model architecture
class ResNet(ImageClassificationBase):
    def __init__(self):
        super().__init__()
        # Use a pretrained model
        self.network = models.resnet50(pretrained=True)
        # Replace last layer
        num_ftrs = self.network.fc.in_features
        self.network.fc = nn.Linear(num_ftrs, len(classes))

    def forward(self, xb):
        return torch.sigmoid(self.network(xb))


model = ResNet()
model_path = "model.pth"
# # Load the state_dict from the .pth file
# state_dict = torch.load(model_path)

# Load the state_dict from the .pth file
state_dict = torch.load(
    "model.pth",
    map_location=torch.device("cuda" if torch.cuda.is_available() else "cpu"),
)


# Load the state_dict into the model
model.load_state_dict(state_dict)

# Set the model to evaluation mode
model.eval()

# Move the model to the appropriate device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)


def get_model():
    return model


def to_device(data, device):
    """Move tensor(s) to chosen device"""
    if isinstance(data, (list, tuple)):
        return [to_device(x, device) for x in data]
    return data.to(device, non_blocking=True)


def predict_image(img, model):
    # Convert to a batch of 1
    xb = to_device(img.unsqueeze(0), device)
    # Get predictions from model
    yb = model(xb)
    print(yb)
    # Pick index with highest probability
    prob, preds = torch.max(yb, dim=1)
    # Retrieve the class label
    return classes[preds[0].item()]


from PIL import Image
import torchvision.transforms as transforms
import matplotlib.pyplot as plt

# %matplotlib inline


def predictImagePath(path):
    image_path = path
    transformations = transforms.Compose(
        [transforms.Resize((256, 256)), transforms.ToTensor()]
    )
    image = Image.open(image_path)
    example_image = transformations(image)
    # plt.imshow(example_image.permute(1, 2, 0))
    return predict_image(example_image, model)


def predict_image_from_file(image_contents):
    # Load the image using PIL
    image = Image.open(io.BytesIO(image_contents))

    # Convert image to tensor
    transformations = transforms.Compose(
        [transforms.Resize((256, 256)), transforms.ToTensor()]
    )
    example_image = transformations(image)

    # Get the prediction
    return predict_image(example_image, model)


from fastapi import FastAPI, File, UploadFile
from typing import Annotated

# from fastapi.middleware.cors import CORSMiddleware

from PIL import Image
import io

app = FastAPI()

# # allow the front end to communicate with the backend
# origins = ["http://localhost:8000"]

# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=origins,
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )
